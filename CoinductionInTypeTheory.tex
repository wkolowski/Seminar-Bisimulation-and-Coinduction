\documentclass{beamer}

\title{Coinduction in type theory: a quick introduction}
\author{Wojciech KoÅ‚owski}
\date{14 March 2022}

\usetheme{Darmstadt}

\begin{document}

\frame{\titlepage}
\frame{\tableofcontents}

\section{Approaches to coinduction}

\begin{frame}{Approaches to coinduction 1/2}
\begin{itemize}
	\item There are quite a few approaches to coinduction:
	\item The LTS approach (LTS is an abbreviation of ``labeled transition system''), in which coinductive processes are (re)presented using a particular kind of state machine.
	\item The categorical approach, in which coinductively defined objects are represented as final coalgebras of endofunctors.
	\item The order-theoretic approach, in which coinductive objects are represented as greatest fixed-points of monotone functions - this is a variant of the categorical approach.
	\item You can find more about the history of the concept of coinduction in \href{https://dl.acm.org/doi/pdf/10.1145/1516507.1516510}{\color{blue}{On the Origins of Bisimulation and
  Coinduction}}.
\end{itemize}
\end{frame}

\begin{frame}{Approaches to coinduction 2/2}
\begin{itemize}
	\item The above approaches are not very enlightening, arguably.
	\item I think that the most natural way of explaining coinduction is to refer to an informal version of the duality with induction, explain it in depth and then present lots of examples and exercises to build the right intuitions. We will do just that!
  \item But we don't want to hand-weave ourselves to death, so later we will see how coinduction works in type theory, particularly in the Coq proof assistant.
  \item These slides are a shortened version of \url{https://github.com/wkolowski/Seminar-Bisimulation-and-Coinduction/blob/master/TalkSlides.pdf} -- see there for a critique of other approaches to coinduction and for an interesting connection between coinduction and topology.
\end{itemize}
\end{frame}

\section{An intuitive approach to coinduction}

\begin{frame}{The duality}
\begin{tabular}{ | p{3cm} | p{3cm} | p{3cm} | }
	\hline
	feature $\downarrow$ & induction & coinduction \\\hline
	shape & sum (of products) & product (of sums) \\\hline
	basic activity & construction & deconstruction (observation) \\\hline
	derived activity & deconstruction (observation) & construction \\\hline
	easy to define functions with & inductive domain & coinductive codomain \\\hline
	such that every (co)recursive call & shrinks the principal argument & grows the result \\\hline
	thus these functions are & terminating & productive \\\hline
	evaluation & possibly eager & necessarily lazy \\\hline
	term height as tree & necessarily finite & possibly infinite \\\hline
\end{tabular}
\end{frame}

\begin{frame}{A comparatory example}
\begin{itemize}
	\item How does the duality play out in practice? Let's see an example in Coq!
	\item The code snippet with the example is available from the GitHub repo of this talk: \url{https://github.com/wkolowski/Seminar-Bisimulation-and-Coinduction/blob/master/Duality.v} (beware: no comments in the code).
\end{itemize}
\end{frame}

\begin{frame}{Explaining the first half of the duality 1/2}
\begin{itemize}
	\item Inductives are determined by ways of constructing their elements and the elimination principle is a derived notion whose purpose is to say ``the only things you can build come from the introduction principles (constructors)''.
	\item Coinductives are determined by ways of observing their elements and the introduction principle is a derived notion whose purpose is to say ``the only things you can observe come from the elimination principles''.
	\item For programmers this basically means that inductives are data (similar to the stuff stored in databases), whereas coinductives are interactive processes (like operating systems or web servers).
\end{itemize}
\end{frame}

\begin{frame}{Explaining the first half of the duality 2/2}
\begin{itemize}
	\item The type \texttt{bool} is an inductive type with two constructors \texttt{true} and \texttt{false}. Knowing this we can derive an elimination principle, which amounts to an \texttt{if-then-else} expression (but dependently typed!).
	\item Imagine a type of web servers that can only handle requests for pictures of funny cats (this is the elimination principle). From this description we know that there must be something in the web server that is responsible for handling these requests and thus the derived introduction principle specifies all the possible ways of constructing that thing.
\end{itemize}
\end{frame}

\begin{frame}{Explaining the second half of the duality}
\begin{itemize}
	\item The second half of the duality is quite clear and doesn't need to be demystified as much as the first, but there are two philosophical misconceptions to be addressed.
	\item The first is about lazy and strict languages.
	\item The second is about ``infinite loops''.
\end{itemize}
\end{frame}

\begin{frame}{Laziness and strictness 1/3}
\begin{itemize}
	\item Inductives can be evaluated both lazily and eagerly, buth since they are data which is most often meant to be passed to some function for further processing, it makes more sense for them to be eager.
	\item Because coinductives are possibly infinite, they can't be evaluated eagerly and thus any language that incorporates them will have some form of lazy evaluation.
	\item We may think that inductive types are (or at least should) be ``eager'', whereas coinductive types are ``lazy''.
\end{itemize}
\end{frame}

\begin{frame}{Laziness and strictness 2/3}
\begin{itemize}
	\item An interesting case is the product type, which can be defined both inductively and coinductively.
	\item Elements of inductive products are constructed by pairing two things. The derived eliminator says that we can pattern match on the pair to get them back and then use them to construct something else.
	\item Elements of coinductive products are eliminated using projections. The derived introduction rule says that we must provide everything that can be projected out, so it too amounts to pairing.
	\item Both product types are isomorphic, but inductive products are best thought of as ``eager products'', whereas coinductive products are best thought of as ``lazy products''.
\end{itemize}
\end{frame}

\begin{frame}{Lazines and strictness 3/3}
\begin{itemize}
	\item \textbf{Laziness and strictness are best thought of as properties of types, not of languages}
	\item Haskell is usually said to be a ``lazy language'', but in reality it's just that its types are lazy by default. Given some strictness annotations we can define strict types or even mixed strict-lazy types.
	\item OCaml or StandardML are usually said to be ``strict'' languages, but it's just that their types are strict by default. We can make the type \texttt{'a} lazy by turning it into a function type with unit domain: \texttt{unit -> 'a}.
	\item In Coq, inductive types are best thought of as strict, whereas coinductive types are best thought of as lazy.
\end{itemize}
\end{frame}

\begin{frame}{Termination and productivity 1/3}
\begin{itemize}
	\item In programmers' collective consciousness there is the term ``infinite loop'', usually applied to describe two kinds of programs.
	\item The first kind looks like \texttt{while(true) $\lbrace$...$\rbrace$}. In such cases the ``infinite loop'' was programmed intentionally. Its purpose may be to, for example, implement a server that is waiting for requests.
	\item The second kind looks like an ordinary loop, but the stopping condition will never be met. In such cases the ``infinite loop'' was programmed by mistake and thus is a bug.
	\item This term would also be applied to describe an erroneous implementation of recursive factorial on integers with the base case missing, even though no loop was used there.
	\item Note that this term is very one-sided -- terminating programs aren't called ``finite loops''.
\end{itemize}
\end{frame}

\begin{frame}{Termination and productivity 2/3}
\begin{itemize}
	\item \textbf{The term ``infinite loop'' is considered harmful, because it conflates two separate notions: termination and productivity.}
	\item Termination is a property that pertains only to recursive functions.
	\item In Coq and type theory, each recursive call must shrink the input and may produce a part of the output.
	\item Therefore all recursive functions terminate.
	\item Productivity is a property that pertains only to corecursive functions.
	\item In Coq and type theory, each corecursive call may do anything with the input and must produce a part of the output.
	\item Therefore all corecursive functions are productive.
\end{itemize}
\end{frame}

\begin{frame}{Termination and productivity 3/3}
\begin{itemize}
	\item To sum it up:
	\item Bugged implementation of factorial on integers without the base case: recursive, nonterminating, not ok.
	\item Correct implementation of factorial on natural numbers: recursive, terminating, ok.
	\item Correct implementation of a web server that serves pictures of funny cats: corecursive, productive, ok.
	\item A web server that hangs for requests of funny cat pictures in which the cat is upside-down: corecursive, nonproductive, not ok.
\end{itemize}
\end{frame}

\section{Coinduction in type theory}

\begin{frame}{A closer look at the duality 1/2}
\begin{itemize}
	\item Earlier we said that for an inductive type $I$ it's easy to define functions of type $I \to X$, whereas for a coinductive type $C$ it's easy to define functions $X \to C$.
	\item To define functions $I \to X$, we use the elimination principle, which for inductive types is called the induction principle.
	\item To define functions of type $X \to C$, we use the introduction principle, which for coinductive types is called the corecursion principle.
	\item There are two troubles with this part of the duality.
  \item The first trouble lies in names: ``induction principle'' vs ``corecursion principle''. Where is the coinduction principle?
\end{itemize}
\end{frame}

\begin{frame}{A closer look at the duality 2/2}
\begin{itemize}
  \item As our running example of $I$, we will use $\texttt{nat}$, the natural numbers.
  \item As our running example of $C$, we will use $\texttt{conat}$, the conatural numbers (see \href{https://github.com/wkolowski/Seminar-Bisimulation-and-Coinduction/blob/master/Duality.v}{\color{blue}{here}} for the definition).
  \item The induction principle for \texttt{nat} looks like this (in Coq): \texttt{forall P :\ nat -> Type, \\ P 0 -> (forall n :\ nat, P n -> P (S n)) -> \\ forall n :\ nat, P n}
  \item The corecursion principle for \texttt{conat} looks like this (in Coq): \texttt{forall X :\ Type, (X -> option X) -> X -> conat}
  \item The second trouble with the duality lies in the strong assymmetry between the two principles: they look nothing like each other's mirror images.
\end{itemize}
\end{frame}

\begin{frame}{A different look at the induction principle 1/2}
\begin{itemize}
	\item To rescue the duality, we have to squint at the induction principle and reformulate it in terms more amenable to being dualized -- we need to split it into a recursion principle and a uniqueness principle.
	\item The recursion principle states that there is a function (called the recursor) \\
	\texttt{rec :\ forall X :\ Type, X -> (X -> X) -> nat -> X} \\
  which for all \texttt{X :\ Type}, \texttt{z :\ X} and \texttt{s :\ X -> X} \\
  satisfies the following equations definitionally: \\
	\texttt{rec X z s 0 $\equiv$ z} \\
	\texttt{rec X z s (S n) $\equiv$ s (rec X z s n)} \\
\end{itemize}
\end{frame}

\begin{frame}{A different look at the induction principle 2/2}
\begin{itemize}
	\item The uniqueness principle is as follows. Given \texttt{X :\ Type} and two functions \texttt{f :\ nat -> X} and \texttt{g :\ nat -> X}, if for all \texttt{z :\ X} and \texttt{s :\ X -> X} they satisfy the same equations as \texttt{rec X z s} (but this time propositionally, i.e. using \texttt{=} instead of $\equiv$), then \texttt{forall n :\ nat, f n = g n}.
  \item An alternative formulation, which involves only a single function, is as follows: if \texttt{f :\ nat -> X} satisfies the same equations as \texttt{rec X z s}, then \\
  \texttt{forall n :\ nat, f n = rec X z s n}.
  \item We could also formulate variants of the uniqueness principle that uses $\equiv$ instead of \texttt{=}, but this is a very confusing territory, so we won't discuss it'll omit it.
\end{itemize}
\end{frame}

\begin{frame}{The coinduction principle 1/2}
\begin{itemize}
	\item We can now state the coinduction principle (for conatural numbers) and see the duality in full glory.
	\item The corecursion principle states that there is a function (called the corecursor) \\
	\texttt{corec :\ forall X, (X -> option X) -> X -> conat} \\
  which for all \texttt{X :\ Type} and \texttt{p :\ X -> option X} \\
  satisfies the following equation definitionally: \\
	\texttt{pred (corec X p x) $\equiv$ \\
	match p x with \\
	| None => None \\
	| Some x' => Some (corec X p x') \\
	end}
\end{itemize}
\end{frame}

\begin{frame}{The coinduction principle 2/2}
\begin{itemize}
	\item The uniqueness principle is as follows. Given \texttt{X :\ Type} and two functions \texttt{f :\ X -> conat} and \texttt{g :\ X -> conat}, if for all \texttt{p :\ X -> option X} they satisfy the same equations as \texttt{corec X p} (but this time propositionally, i.e. using \texttt{=} instead of $\equiv$), then \texttt{forall x :\ X, f x = g x}.
  \item An alternative formulation: if \texttt{f :\ X -> conat} satisfies the same equations as \texttt{corec X p}, then \\
  \texttt{forall x :\ X, f x = corec X p x}.
\end{itemize}
\end{frame}

\begin{frame}{Meaning of the coinduction principle}
\begin{itemize}
	\item Meaning of the corecursor is quite clear -- it's for making functions into coinductives. But what is the (hidden) meaning of the uniqueness principle?
	\item To understand it, we need to notice that, even though it is a statement about \textbf{functions} into coinductives, in reality it says something about equality of \textbf{elements} of coinductives.
	\item For conatural numbers, it states that two numbers are equal if they both have equal predecessors, and their predecessors have equal predecessors and so on.
	\item For streams, it would state that two streams are equal if they have equal heads and their tails have equal heads and so on.
	\item So, the uniqueness principle states that bisimilar numbers/streams/structures are equal.
\end{itemize}
\end{frame}

\begin{frame}{Induction, recursion, uniqueness}
\begin{itemize}
	\item The recursion and uniqueness principles are independent -- they can't be derived from each other.
	\item They can, however, be derived from the induction principle: the recursion principle is a non-dependent special case of the induction principle and the uniqueness principle can be easily proved by using the appropriate equations and induction hypotheses.
	\item Likewise, the induction principle can be derived when we have both the recursion principle and the uniqueness principle, but the proof is a bit more involved.
\end{itemize}
\end{frame}

\begin{frame}{Coinduction, corecursion, uniqueness}
\begin{itemize}
	\item The corecursion and uniqueness principles are independent too. When considered together, they can be thought of as the coinduction principle.
	\item Therefore in Coq, because we only have the corecursion principle, we can't derive the uniqueness principle in any way.
	\item How to prove \texttt{forall x :\ X, f x = g x}, for \texttt{f g :\ X -> C} and \texttt{C} coinductive?
	\item Because the equality type is inductive, we can't use corecursion and because we don't know anything about \texttt{X}, we can't do anything with it either.
	\item Therefore we are stuck without the uniqueness principle. In Coq, we can't prove bisimilar objects equal without assuming axioms.
\end{itemize}
\end{frame}

\begin{frame}{How to add (co)inductive types to type theory?}
\begin{itemize}
	\item In set theory, coinductive definitions are not a basic concept and have to be derived from the axioms. Inductives aren't basic either.
	\item What's the situation in Coq and type theory in general?
	\item There are three approaches that I'm aware of: schematic definitions, W-types/M-types and universes of codes.
\end{itemize}
\end{frame}

\begin{frame}{Schematic definitions}
\begin{itemize}
	\item In Coq, (co)inductives come from schematic definitions using the keyword \texttt{(Co)Inductive}.
	\item After issuing such a definition, appropriate rules for the defined type are added to the environment.
	\item Pros: direct.
	\item Cons: defining a (co)inductive type is a side effect! This can be seen e.g. in a parameterized module in which we define a (co)inductive type. Then two modules defined by instantiating the parameters contain two copies of the same (co)inductive type which are different.
	\item Another cons: schematic definitions are hard to formally describe and therefore they are usually found in implementations, not in papers.
\end{itemize}
\end{frame}

\begin{frame}{W-types, M-types}
\begin{itemize}
	\item Another approach to adding inductives/coinductives are the so called W-types/M-types, respectively.
	\item The idea is to add a single parameterized type \texttt{W} whose elements are well-founded trees.
	\item The parameters control the shape of the trees -- the branching, types of non-recursive arguments etc. Particular inductive types can be recovered by instantiating \texttt{W} with the appropriate parameters.
	\item The type \texttt{M} is dual to \texttt{W} and can be used to represent coinductives. Its elements are possibly non-well-founded trees.
	\item Pros: one ring to rule them all, simple to describe formally.
	\item Cons: encodings using \texttt{W} and \texttt{M} have some overhead.
	\item Cons: \texttt{W} and \texttt{M} are inherently higher-order, which means we need functional extensionality for equality proofs to go through.
\end{itemize}
\end{frame}

\begin{frame}{Universes of codes}
\begin{itemize}
	\item Another idea is to have an (inductive) type, whose elements are ``codes'', and a function that interprets these codes as real inductive/coinductive types.
	\item This is basically a defunctionalization of \texttt{W} and \texttt{M}.
	\item Pros: one ring to rule them all, first-order so no problems with functional extensionality, not an encoding.
	\item Cons: harder to formally describe than \texttt{W} and \texttt{M}.
	\item See the paper \href{http://jmchapman.io/papers/levitation.pdf}{\color{blue}{The gentle art of levitation}} for more.
\end{itemize}
\end{frame}

\begin{frame}{Snippet}
\begin{itemize}
	\item Code snippets that illustrate how schematic definitions are side-effecting and how the definitions of \texttt{W} and \texttt{M} look like can be found in the file \url{https://github.com/wkolowski/Seminar-Bisimulation-and-Coinduction/blob/master/SchematicWM.v}.
\end{itemize}
\end{frame}

\section{Exercises}

\begin{frame}{Exercises}
\begin{itemize}
	\item The best way to learn coinduction is by using it.
	\item As an exercise, try to develop the theory of conatural numbers: \url{https://github.com/wkolowski/Seminar-Bisimulation-and-Coinduction/blob/master/ConaturalExercises.v}.
\end{itemize}
\end{frame}

\end{document}